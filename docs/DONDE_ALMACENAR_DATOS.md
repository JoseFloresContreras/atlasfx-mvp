# D√≥nde Almacenar los Datos - An√°lisis de Opciones

**Fecha:** 20 de Octubre, 2025  
**Versi√≥n:** 1.0  
**Prop√≥sito:** Evaluar las 3 mejores opciones para almacenar datos del proyecto AtlasFX MVP

---

## Contexto del Proyecto

AtlasFX es un sistema de trading algor√≠tmico que utiliza:
- **Datos Level 1 tick data** de Dukascopy (forex)
- **Pipeline de datos** que procesa, limpia, agrega y genera features
- **Modelos de ML** (VAE, TFT, SAC) que requieren acceso r√°pido a datos procesados
- **Experimentos ML** que necesitan versionado de datos
- **Backtesting** que requiere acceso hist√≥rico completo

### Requerimientos de Almacenamiento

1. **Volumen de Datos:**
   - Tick data crudo: ~100GB+ por a√±o (7 pares de forex)
   - Datos agregados: ~10GB por a√±o
   - Features procesadas: ~5GB por a√±o
   - Modelos entrenados: ~1-5GB

2. **Patrones de Acceso:**
   - Lectura secuencial para entrenamiento (alto throughput)
   - Lectura aleatoria para backtesting (baja latencia)
   - Escritura por lotes (pipeline de datos)
   - Versionado de datos y modelos

3. **Requisitos No Funcionales:**
   - Reproducibilidad (versiones inmutables)
   - Costo-efectivo para desarrollo MVP
   - Escalable para producci√≥n futura
   - Compatible con Python/PyTorch ecosystem
   - Backup y recuperaci√≥n

---

## Opci√≥n 1: DVC + Almacenamiento en la Nube (S3/Google Cloud Storage)

### Descripci√≥n

**DVC (Data Version Control)** es una herramienta de versionado de datos dise√±ada para proyectos de ML. Funciona como Git pero para archivos grandes, almacenando metadata en Git y datos reales en almacenamiento remoto (S3, GCS, Azure Blob).

### Arquitectura Propuesta

```
Local Development
‚îú‚îÄ‚îÄ data/                    # DVC-tracked data (metadata in Git)
‚îÇ   ‚îú‚îÄ‚îÄ raw/                 # Tick data from Dukascopy
‚îÇ   ‚îú‚îÄ‚îÄ processed/           # Aggregated time-series
‚îÇ   ‚îú‚îÄ‚îÄ features/            # Feature matrices
‚îÇ   ‚îî‚îÄ‚îÄ splits/              # Train/val/test splits
‚îú‚îÄ‚îÄ models/                  # DVC-tracked model checkpoints
‚îú‚îÄ‚îÄ .dvc/                    # DVC configuration
‚îî‚îÄ‚îÄ .git/                    # Git repository

Remote Storage (S3/GCS)
‚îî‚îÄ‚îÄ atlasfx-data/
    ‚îú‚îÄ‚îÄ data/                # Actual data files
    ‚îî‚îÄ‚îÄ models/              # Actual model files
```

### Ventajas ‚úÖ

1. **Versionado Nativo:**
   - Cada versi√≥n de datos tiene un hash √∫nico
   - Puedes volver a cualquier versi√≥n hist√≥rica
   - Ideal para reproducibilidad cient√≠fica

2. **Integraci√≥n con Git:**
   - Los cambios en datos se trackean junto con c√≥digo
   - PRs pueden incluir cambios de datos y c√≥digo
   - Workflow familiar para desarrolladores

3. **Escalabilidad:**
   - Almacenamiento en la nube pr√°cticamente ilimitado
   - S3/GCS son altamente disponibles y durables (99.999999999%)
   - F√°cil escalar de MVP a producci√≥n

4. **Costo-Efectivo:**
   - S3 Standard: ~$0.023/GB/mes (primeros 50TB)
   - S3 Glacier (archival): ~$0.004/GB/mes para datos antiguos
   - GCS Standard: ~$0.020/GB/mes
   - Solo pagas por lo que usas

5. **Ecosystem ML:**
   - Compatibilidad nativa con MLflow, Weights & Biases
   - Soporte para Parquet, HDF5, CSV
   - Pipelines de datos reproducibles

6. **Backup Autom√°tico:**
   - Los datos en S3/GCS est√°n replicados autom√°ticamente
   - Versionado inmutable (no puedes borrar por accidente)

### Desventajas ‚ö†Ô∏è

1. **Latencia de Red:**
   - Primer acceso requiere download de datos
   - Necesitas buena conexi√≥n a internet
   - Cache local ayuda pero ocupa disco

2. **Costos de Transferencia:**
   - Download desde S3: ~$0.09/GB (despu√©s de 100GB/mes gratis)
   - GCS: ~$0.12/GB
   - Puede acumularse con experimentos frecuentes

3. **Complejidad Inicial:**
   - Curva de aprendizaje de DVC
   - Setup de credenciales AWS/GCP
   - Configuraci√≥n de permisos (IAM)

4. **Dependencia de Terceros:**
   - Requiere cuenta AWS/GCP
   - Dependes de la disponibilidad del servicio
   - Costos pueden cambiar con el tiempo

### Implementaci√≥n

```bash
# Instalar DVC
pip install dvc[s3]  # o dvc[gs] para Google Cloud

# Inicializar DVC
dvc init

# Configurar remote storage
dvc remote add -d storage s3://atlasfx-data/dvc-store
dvc remote modify storage region us-east-1

# Trackear datos
dvc add data/raw/eurusd_2024.parquet
git add data/raw/eurusd_2024.parquet.dvc .gitignore
git commit -m "Add raw EUR/USD data"

# Push a remote
dvc push

# Pull en otra m√°quina
dvc pull
```

### Costo Estimado (Mensual)

- **Almacenamiento:** 120GB √ó $0.023 = $2.76/mes
- **Transferencia:** 50GB/mes √ó $0.09 = $4.50/mes
- **Total:** ~$7-10/mes para MVP

### Recomendaci√≥n

‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê **ALTAMENTE RECOMENDADO**

**Caso de Uso Ideal:**
- Proyectos ML que requieren reproducibilidad
- Equipos distribuidos (o trabajo en m√∫ltiples m√°quinas)
- Escalabilidad de MVP a producci√≥n
- Presupuesto moderado ($10-50/mes)

---

## Opci√≥n 2: Almacenamiento Local + Git LFS

### Descripci√≥n

**Git LFS (Large File Storage)** es una extensi√≥n de Git que maneja archivos grandes. Los archivos grandes se almacenan en un servidor LFS (GitHub, GitLab, Bitbucket) y Git solo guarda punteros.

### Arquitectura Propuesta

```
Repository
‚îú‚îÄ‚îÄ data/                    # Git LFS tracked
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îî‚îÄ‚îÄ features/
‚îú‚îÄ‚îÄ models/                  # Git LFS tracked
‚îú‚îÄ‚îÄ .gitattributes           # LFS configuration
‚îî‚îÄ‚îÄ .git/
    ‚îî‚îÄ‚îÄ lfs/                 # LFS cache
```

### Ventajas ‚úÖ

1. **Simplicidad:**
   - Git workflow normal
   - No requiere setup de cloud
   - Una sola herramienta (Git)

2. **Integraci√≥n GitHub:**
   - Los datos viven en el mismo repo
   - Clone = c√≥digo + datos
   - F√°cil para colaboradores nuevos

3. **Costo Inicial Bajo:**
   - GitHub: 1GB gratis, $5/mes por 50GB
   - GitLab: 10GB gratis en plan free
   - Bitbucket: 1GB gratis

4. **Sin Dependencias Externas:**
   - No necesitas cuenta AWS/GCP
   - Todo en GitHub/GitLab
   - Menos servicios que administrar

### Desventajas ‚ùå

1. **Limitaciones de Tama√±o:**
   - GitHub LFS: L√≠mite de 2GB por archivo
   - 1GB de ancho de banda gratis/mes
   - Muy limitado para datos de trading (>100GB)

2. **Costo Escalable:**
   - GitHub: $5/mes por 50GB adicionales
   - Para 200GB: ~$20/mes (m√°s caro que S3)
   - Bandwidth charges pueden ser altos

3. **Performance:**
   - M√°s lento que S3 para archivos grandes
   - Clone inicial puede tardar horas
   - No optimizado para ML workloads

4. **No Es Verdadero Versionado:**
   - Git LFS puede tener conflictos
   - Eliminar versiones antiguas es complejo
   - No est√° dise√±ado para datasets grandes

5. **L√≠mites de GitHub:**
   - Repository size max: 100GB (recomendado <5GB)
   - Warnings despu√©s de 1GB
   - No escalable para producci√≥n

### Implementaci√≥n

```bash
# Instalar Git LFS
git lfs install

# Trackear archivos grandes
git lfs track "*.parquet"
git lfs track "*.h5"
git lfs track "*.pth"

# Agregar a Git
git add .gitattributes
git add data/raw/eurusd_2024.parquet
git commit -m "Add data with LFS"
git push
```

### Costo Estimado (Mensual)

- **Almacenamiento:** 120GB ‚Üí $15/mes (GitHub packs)
- **Bandwidth:** 50GB/mes ‚Üí $5/mes
- **Total:** ~$20/mes (m√°s caro que S3)

### Recomendaci√≥n

‚≠ê‚≠ê **NO RECOMENDADO PARA ESTE PROYECTO**

**Caso de Uso Ideal:**
- Proyectos peque√±os (<50GB)
- Equipos que solo usan GitHub
- Datos que cambian poco
- Prototipado r√°pido

**Por qu√© no para AtlasFX:**
- Los datos de tick superan los l√≠mites de GitHub LFS
- M√°s caro que S3 para vol√∫menes grandes
- No optimizado para ML workflows
- Escalabilidad limitada

---

## Opci√≥n 3: Almacenamiento Local + Base de Datos Especializada (TimescaleDB/InfluxDB)

### Descripci√≥n

Usar una **base de datos de series temporales** optimizada para datos financieros. TimescaleDB (PostgreSQL) o InfluxDB est√°n dise√±adas para manejar millones de ticks con queries eficientes.

### Arquitectura Propuesta

```
Database Server (Local o Cloud)
‚îî‚îÄ‚îÄ TimescaleDB
    ‚îú‚îÄ‚îÄ tick_data              # Raw ticks (hypertable)
    ‚îÇ   ‚îú‚îÄ‚îÄ timestamp
    ‚îÇ   ‚îú‚îÄ‚îÄ symbol
    ‚îÇ   ‚îú‚îÄ‚îÄ bid
    ‚îÇ   ‚îú‚îÄ‚îÄ ask
    ‚îÇ   ‚îî‚îÄ‚îÄ volume
    ‚îú‚îÄ‚îÄ aggregated_ohlc        # Pre-aggregated (hypertable)
    ‚îî‚îÄ‚îÄ features               # Processed features

Application Layer
‚îú‚îÄ‚îÄ data-pipeline/
‚îÇ   ‚îî‚îÄ‚îÄ db_loader.py          # ETL to database
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ data_loader.py        # Query features from DB
‚îî‚îÄ‚îÄ experiments/
    ‚îî‚îÄ‚îÄ mlflow/               # Model versioning with MLflow
```

### Ventajas ‚úÖ

1. **Performance Optimizado:**
   - Queries por rango temporal son ultra-r√°pidas
   - √çndices autom√°ticos en timestamp
   - Compresi√≥n de datos (TimescaleDB: 90%+ compression)
   - Agregaciones nativas (OHLC, VWAP)

2. **Queries SQL Potentes:**
   ```sql
   -- Obtener datos de entrenamiento
   SELECT * FROM features 
   WHERE timestamp BETWEEN '2024-01-01' AND '2024-06-30'
   AND symbol = 'EURUSD'
   ORDER BY timestamp;
   
   -- Calcular VWAP on-the-fly
   SELECT time_bucket('5 minutes', timestamp) AS bucket,
          symbol,
          SUM(price * volume) / SUM(volume) AS vwap
   FROM tick_data
   GROUP BY bucket, symbol;
   ```

3. **Versionado con Timestamps:**
   - Datos inmutables (insert-only)
   - Puedes recrear estado en cualquier momento
   - Auditor√≠a completa de cambios

4. **Escalabilidad Vertical:**
   - TimescaleDB escala a billones de filas
   - Puede manejar todo el hist√≥rico de Dukascopy
   - Particionamiento autom√°tico (time-based)

5. **Integraci√≥n Python:**
   - SQLAlchemy, pandas, psycopg2
   - Direct SQL queries desde PyTorch DataLoader
   - Streaming de datos para entrenamiento

6. **Costo-Efectivo (Local):**
   - PostgreSQL/TimescaleDB es open-source
   - Puedes correr en tu propia m√°quina
   - No hay costos de cloud (si es local)

### Desventajas ‚ö†Ô∏è

1. **Setup Complejo:**
   - Requiere administrar un servidor de BD
   - Configuraci√≥n de √≠ndices y particiones
   - Backups manuales necesarios

2. **No Es Versionado Nativo:**
   - No puedes volver a "versiones" como DVC
   - Necesitas snapshots manuales
   - Reproducibilidad requiere disciplina

3. **Backup Cr√≠tico:**
   - Si la BD se corrompe, pierdes todo
   - Necesitas estrategia de backup robusta
   - Disaster recovery m√°s complejo

4. **Memoria y Disco:**
   - Base de datos puede crecer mucho
   - Requiere SSD r√°pido para performance
   - Tuning de PostgreSQL necesario

5. **Limitaciones para ML:**
   - No integraci√≥n nativa con MLflow/W&B
   - Feature store requiere desarrollo custom
   - Versionado de features no es trivial

6. **Escalabilidad Horizontal Limitada:**
   - Scaling a m√∫ltiples m√°quinas es complejo
   - No es serverless (requiere servidor running)

### Implementaci√≥n

```python
# Conexi√≥n a TimescaleDB
import pandas as pd
from sqlalchemy import create_engine

engine = create_engine('postgresql://user:pass@localhost/atlasfx')

# Cargar tick data
df = pd.read_parquet('eurusd_ticks.parquet')
df.to_sql('tick_data', engine, if_exists='append', index=False)

# Query para entrenamiento
query = """
SELECT * FROM features 
WHERE timestamp >= '2024-01-01'::timestamp
AND timestamp < '2024-07-01'::timestamp
ORDER BY timestamp
"""
train_data = pd.read_sql(query, engine)

# Crear hypertable (TimescaleDB)
engine.execute("""
    SELECT create_hypertable('tick_data', 'timestamp',
                             chunk_time_interval => INTERVAL '1 day');
""")
```

### Costo Estimado (Mensual)

**Opci√≥n Local:**
- Hardware: $0 (usa tu m√°quina)
- Almacenamiento: SSD de 512GB (~$50 one-time)
- Electricidad: ~$5/mes
- **Total:** ~$5/mes

**Opci√≥n Cloud (TimescaleDB Cloud):**
- Starter: $50/mes (25GB storage, 0.5 CPU)
- Growth: $200/mes (100GB storage, 2 CPU)
- **Total:** $50-200/mes (muy caro para MVP)

### Recomendaci√≥n

‚≠ê‚≠ê‚≠ê **RECOMENDADO PARA CIERTOS CASOS**

**Caso de Uso Ideal:**
- Sistemas de trading en producci√≥n (latencia cr√≠tica)
- Necesitas queries complejas sobre ticks
- Acceso en tiempo real a datos hist√≥ricos
- Infraestructura local (no cloud)

**Por qu√© podr√≠a no ser ideal para AtlasFX MVP:**
- Complejidad de setup vs. DVC
- No tiene versionado nativo de datasets
- Backup y disaster recovery m√°s dif√≠cil
- Mejor para producci√≥n que para investigaci√≥n

**Cu√°ndo considerarlo:**
- Despu√©s del MVP, para deployment
- Si necesitas backtesting ultra-r√°pido
- Si tienes experiencia con bases de datos

---

## Comparaci√≥n Final

| Criterio | DVC + S3/GCS | Git LFS | TimescaleDB |
|----------|-------------|---------|-------------|
| **Costo (MVP)** | $7-10/mes | $20/mes | $5/mes (local) |
| **Escalabilidad** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excelente | ‚≠ê‚≠ê Limitada | ‚≠ê‚≠ê‚≠ê‚≠ê Muy buena |
| **Versionado** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Nativo | ‚≠ê‚≠ê‚≠ê B√°sico | ‚≠ê‚≠ê Manual |
| **Performance** | ‚≠ê‚≠ê‚≠ê‚≠ê Muy bueno | ‚≠ê‚≠ê‚≠ê Bueno | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excelente |
| **Facilidad Setup** | ‚≠ê‚≠ê‚≠ê‚≠ê F√°cil | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Muy f√°cil | ‚≠ê‚≠ê Complejo |
| **Reproducibilidad** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Perfecta | ‚≠ê‚≠ê‚≠ê Buena | ‚≠ê‚≠ê‚≠ê Requiere disciplina |
| **ML Ecosystem** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Perfecto | ‚≠ê‚≠ê‚≠ê Aceptable | ‚≠ê‚≠ê‚≠ê Custom integration |
| **Backup** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Autom√°tico | ‚≠ê‚≠ê‚≠ê‚≠ê Incluido | ‚≠ê‚≠ê Manual |
| **Complejidad** | ‚≠ê‚≠ê‚≠ê Media | ‚≠ê‚≠ê‚≠ê‚≠ê Baja | ‚≠ê‚≠ê Alta |

---

## Recomendaci√≥n Final

### ü•á **Ganador: DVC + AWS S3 (o Google Cloud Storage)**

#### Justificaci√≥n

Para el MVP de AtlasFX, **DVC + S3** es la mejor opci√≥n porque:

1. **Reproducibilidad Cient√≠fica:**
   - El proyecto requiere est√°ndares de nivel doctoral
   - DVC provee versionado inmutable de datasets
   - Puedes volver a cualquier experimento hist√≥rico

2. **Costo-Efectivo:**
   - ~$7-10/mes es muy econ√≥mico para MVP
   - Escala linealmente (pagas solo lo que usas)
   - No hay sorpresas en la factura

3. **Ecosystem ML:**
   - Integraci√≥n nativa con MLflow, Weights & Biases
   - Compatible con PyTorch DataLoaders
   - Soporte para Parquet, HDF5 (formatos eficientes)

4. **Escalabilidad:**
   - De MVP a producci√≥n sin cambios de arquitectura
   - S3 puede manejar petabytes si es necesario
   - Alta disponibilidad y durabilidad

5. **Bajo Riesgo:**
   - Backup autom√°tico (99.999999999% durability)
   - No dependes de una sola m√°quina
   - F√°cil colaboraci√≥n (m√∫ltiples desarrolladores)

### Implementaci√≥n Recomendada (Fase 1)

```bash
# Semana 1: Setup DVC
pip install dvc[s3]
dvc init
dvc remote add -d storage s3://atlasfx-mvp-data/dvc-store

# Semana 2: Migrar datos existentes
dvc add data/raw/
dvc add data/processed/
dvc push
git commit -m "Add data versioning with DVC"

# Semana 3+: Workflow normal
# 1. Procesar datos
python data-pipeline/pipeline.py

# 2. Versionar resultados
dvc add data/features/v1.0.parquet
git add data/features/v1.0.parquet.dvc
git commit -m "Add features v1.0"
dvc push

# 3. Entrenar modelo
python train_vae.py --data-version v1.0

# 4. Versionar modelo
dvc add models/vae_best.pth
git add models/vae_best.pth.dvc
git commit -m "Add trained VAE"
dvc push
```

### Migraci√≥n Futura (Post-MVP)

Cuando el proyecto pase a producci√≥n:
1. **Mantener DVC + S3** para:
   - Versionado de datasets de entrenamiento
   - Reproducibilidad de experimentos
   - Backup de modelos

2. **Agregar TimescaleDB** para:
   - Datos en tiempo real (tick stream)
   - Queries de backtesting r√°pidos
   - Monitoreo de performance en producci√≥n

3. **Arquitectura H√≠brida:**
   ```
   Research/Training: DVC + S3 (versionado)
   Production/Live: TimescaleDB (latencia baja)
   Backup: S3 Glacier (archival)
   ```

### Alternativa Econ√≥mica (Si presupuesto es $0)

Si no puedes pagar $10/mes:
1. **Usar almacenamiento local** con DVC (sin remote)
2. **Backups manuales** a disco externo
3. **Git LFS** solo para datos cr√≠ticos (<5GB)
4. **Migrar a S3** cuando tengas presupuesto

---

## Conclusi√≥n

**Para AtlasFX MVP, la recomendaci√≥n es:**

### ‚úÖ Implementar: DVC + AWS S3

**Razones:**
- Mejor balance costo/beneficio/complejidad
- Alineado con est√°ndares de ML research
- Escalable de 120GB a terabytes
- Integraci√≥n con herramientas modernas de ML
- Reproducibilidad garantizada

**Next Steps:**
1. Crear cuenta AWS (free tier: 5GB gratis)
2. Setup S3 bucket con lifecycle policies
3. Instalar y configurar DVC
4. Migrar datos actuales
5. Documentar workflow en README

**Costo Total:**
- **MVP (primeros 6 meses):** ~$50-60
- **Producci√≥n (a√±o 1):** ~$100-200/a√±o

**ROI:** El tiempo ahorrado en debugging y reproducibilidad vale mucho m√°s que $10/mes.

---

**Autor:** An√°lisis para AtlasFX MVP  
**Fecha:** Octubre 2025  
**Versi√≥n:** 1.0
