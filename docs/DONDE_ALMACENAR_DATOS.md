# D√≥nde Almacenar los Datos - An√°lisis de Opciones

**Fecha:** 20 de Octubre, 2025  
**Versi√≥n:** 1.0  
**Prop√≥sito:** Evaluar las 3 mejores opciones para almacenar datos del proyecto AtlasFX MVP

---

## Contexto del Proyecto

AtlasFX es un sistema de trading algor√≠tmico que utiliza:
- **Datos Level 1 tick data** de Dukascopy (forex)
- **Pipeline de datos** que procesa, limpia, agrega y genera features
- **Modelos de ML** (VAE, TFT, SAC) que requieren acceso r√°pido a datos procesados
- **Experimentos ML** que necesitan versionado de datos
- **Backtesting** que requiere acceso hist√≥rico completo

### Requerimientos de Almacenamiento

1. **Volumen de Datos:**
   - Tick data crudo: ~100GB+ por a√±o (7 pares de forex)
   - Datos agregados: ~10GB por a√±o
   - Features procesadas: ~5GB por a√±o
   - Modelos entrenados: ~1-5GB

2. **Patrones de Acceso:**
   - Lectura secuencial para entrenamiento (alto throughput)
   - Lectura aleatoria para backtesting (baja latencia)
   - Escritura por lotes (pipeline de datos)
   - Versionado de datos y modelos

3. **Requisitos No Funcionales:**
   - Reproducibilidad (versiones inmutables)
   - Costo-efectivo para desarrollo MVP
   - Escalable para producci√≥n futura
   - Compatible con Python/PyTorch ecosystem
   - Backup y recuperaci√≥n

---

## Opci√≥n 1: DVC + Almacenamiento en la Nube (S3/Google Cloud Storage)

### Descripci√≥n

**DVC (Data Version Control)** es una herramienta de versionado de datos dise√±ada para proyectos de ML. Funciona como Git pero para archivos grandes, almacenando metadata en Git y datos reales en almacenamiento remoto (S3, GCS, Azure Blob).

### Arquitectura Propuesta

```
Local Development
‚îú‚îÄ‚îÄ data/                    # DVC-tracked data (metadata in Git)
‚îÇ   ‚îú‚îÄ‚îÄ raw/                 # Tick data from Dukascopy
‚îÇ   ‚îú‚îÄ‚îÄ processed/           # Aggregated time-series
‚îÇ   ‚îú‚îÄ‚îÄ features/            # Feature matrices
‚îÇ   ‚îî‚îÄ‚îÄ splits/              # Train/val/test splits
‚îú‚îÄ‚îÄ models/                  # DVC-tracked model checkpoints
‚îú‚îÄ‚îÄ .dvc/                    # DVC configuration
‚îî‚îÄ‚îÄ .git/                    # Git repository

Remote Storage (S3/GCS)
‚îî‚îÄ‚îÄ atlasfx-data/
    ‚îú‚îÄ‚îÄ data/                # Actual data files
    ‚îî‚îÄ‚îÄ models/              # Actual model files
```

### Ventajas ‚úÖ

1. **Versionado Nativo:**
   - Cada versi√≥n de datos tiene un hash √∫nico
   - Puedes volver a cualquier versi√≥n hist√≥rica
   - Ideal para reproducibilidad cient√≠fica

2. **Integraci√≥n con Git:**
   - Los cambios en datos se trackean junto con c√≥digo
   - PRs pueden incluir cambios de datos y c√≥digo
   - Workflow familiar para desarrolladores

3. **Escalabilidad:**
   - Almacenamiento en la nube pr√°cticamente ilimitado
   - S3/GCS son altamente disponibles y durables (99.999999999%)
   - F√°cil escalar de MVP a producci√≥n

4. **Costo-Efectivo:**
   - S3 Standard: ~$0.023/GB/mes (primeros 50TB)
   - S3 Glacier (archival): ~$0.004/GB/mes para datos antiguos
   - GCS Standard: ~$0.020/GB/mes
   - Solo pagas por lo que usas

5. **Ecosystem ML:**
   - Compatibilidad nativa con MLflow, Weights & Biases
   - Soporte para Parquet, HDF5, CSV
   - Pipelines de datos reproducibles

6. **Backup Autom√°tico:**
   - Los datos en S3/GCS est√°n replicados autom√°ticamente
   - Versionado inmutable (no puedes borrar por accidente)

### Desventajas ‚ö†Ô∏è

1. **Latencia de Red:**
   - Primer acceso requiere download de datos
   - Necesitas buena conexi√≥n a internet
   - Cache local ayuda pero ocupa disco

2. **Costos de Transferencia:**
   - Download desde S3: ~$0.09/GB (despu√©s de 100GB/mes gratis)
   - GCS: ~$0.12/GB
   - Puede acumularse con experimentos frecuentes

3. **Complejidad Inicial:**
   - Curva de aprendizaje de DVC
   - Setup de credenciales AWS/GCP
   - Configuraci√≥n de permisos (IAM)

4. **Dependencia de Terceros:**
   - Requiere cuenta AWS/GCP
   - Dependes de la disponibilidad del servicio
   - Costos pueden cambiar con el tiempo

### Implementaci√≥n

```bash
# Instalar DVC
pip install dvc[s3]  # o dvc[gs] para Google Cloud

# Inicializar DVC
dvc init

# Configurar remote storage
dvc remote add -d storage s3://atlasfx-data/dvc-store
dvc remote modify storage region us-east-1

# Trackear datos
dvc add data/raw/eurusd_2024.parquet
git add data/raw/eurusd_2024.parquet.dvc .gitignore
git commit -m "Add raw EUR/USD data"

# Push a remote
dvc push

# Pull en otra m√°quina
dvc pull
```

### Costo Estimado (Mensual)

- **Almacenamiento:** 120GB √ó $0.023 = $2.76/mes
- **Transferencia:** 50GB/mes √ó $0.09 = $4.50/mes
- **Total:** ~$7-10/mes para MVP

### Recomendaci√≥n

‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê **ALTAMENTE RECOMENDADO**

**Caso de Uso Ideal:**
- Proyectos ML que requieren reproducibilidad
- Equipos distribuidos (o trabajo en m√∫ltiples m√°quinas)
- Escalabilidad de MVP a producci√≥n
- Presupuesto moderado ($10-50/mes)

---

## Opci√≥n 2: Almacenamiento Local Puro

### Descripci√≥n

**Almacenamiento completamente local** en tu PC dedicado, sin sincronizaci√≥n con cloud. Los datos viven √∫nicamente en discos locales con backups manuales a discos externos.

### Especificaciones del Sistema

**Hardware Disponible:**
- 1TB de espacio exclusivo para el proyecto
- SSD o HDD (TBD - importante para performance)

**Estimaciones de Datos:**
- **Raw tick data:** ~100GB (7 pares + 3 instrumentos, 4 a√±os)
- **Aggregated k-lines:** ~10-20GB (1-10 min intervals)
- **Features procesadas:** ~5-10GB (200-500 features estimadas)
- **Modelos entrenados:** ~5GB (VAE, TFT, SAC checkpoints)
- **Experiments logs:** ~10GB (MLflow/W&B artifacts)
- **Total estimado:** ~130-145GB

**Espacio disponible despu√©s:** ~855-870GB (suficiente para crecer 6-7x)

### Arquitectura Propuesta

```
/home/user/atlasfx-data/          # Directorio ra√≠z (1TB disk)
‚îú‚îÄ‚îÄ raw/                           # Raw tick data (~100GB)
‚îÇ   ‚îú‚îÄ‚îÄ forex/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ EURUSD/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ GBPUSD/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ instruments/
‚îÇ       ‚îú‚îÄ‚îÄ XAUUSD/  # Gold
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ processed/                     # Aggregated k-lines (~10-20GB)
‚îÇ   ‚îú‚îÄ‚îÄ 1min/
‚îÇ   ‚îú‚îÄ‚îÄ 5min/
‚îÇ   ‚îî‚îÄ‚îÄ 10min/
‚îú‚îÄ‚îÄ features/                      # Feature matrices (~5-10GB)
‚îÇ   ‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îú‚îÄ‚îÄ val/
‚îÇ   ‚îî‚îÄ‚îÄ test/
‚îú‚îÄ‚îÄ models/                        # Trained models (~5GB)
‚îÇ   ‚îú‚îÄ‚îÄ vae/
‚îÇ   ‚îú‚îÄ‚îÄ tft/
‚îÇ   ‚îî‚îÄ‚îÄ sac/
‚îú‚îÄ‚îÄ experiments/                   # MLflow logs (~10GB)
‚îÇ   ‚îî‚îÄ‚îÄ mlruns/
‚îî‚îÄ‚îÄ backups/                       # Manual backups
    ‚îî‚îÄ‚îÄ weekly_snapshots/
```

### Ventajas ‚úÖ

1. **Costo Cero**
   - No hay costos mensuales de cloud
   - Hardware ya disponible
   - Ideal para MVP con presupuesto limitado

2. **Velocidad de Acceso**
   - Latencia ultra-baja (especialmente con SSD)
   - No dependes de ancho de banda de internet
   - I/O directo sin API calls

3. **Privacidad Total**
   - Datos no salen de tu m√°quina
   - No requieres cuenta AWS/GCP
   - No hay riesgos de leak de datos

4. **Simplicidad**
   - No requiere setup de DVC, S3, credenciales
   - File system normal (cp, mv, rsync)
   - Menos moving parts = menos cosas que romper

5. **Sin L√≠mites de Transferencia**
   - No pagas por download/upload
   - Puedes iterar libremente sin preocuparte por costos
   - Ideal para fase de experimentaci√≥n intensiva

6. **Patr√≥n de Acceso Ideal**
   - ‚úÖ Raw data se accede **UNA VEZ** durante pipeline
   - ‚úÖ Features procesadas se acceden durante entrenamiento
   - ‚úÖ Despu√©s del pipeline, raw data queda en "cold storage"
   - ‚úÖ No necesitas acceso frecuente despu√©s de generar features

### Desventajas ‚ùå

1. **No Hay Versionado Nativo**
   - Sin DVC, no tienes versiones autom√°ticas de datasets
   - Debes implementar versionado manual (timestamps, git tags)
   - Reproducibilidad requiere disciplina

2. **Riesgo de P√©rdida de Datos**
   - Si el disco se da√±a, pierdes todo
   - Requiere estrategia de backup robusta
   - Single point of failure

3. **No Colaborativo**
   - Solo t√∫ tienes acceso a los datos
   - Si trabajas en otra m√°quina, debes copiar manualmente
   - No hay sincronizaci√≥n autom√°tica

4. **No Escalable a Producci√≥n**
   - En producci√≥n necesitar√°s cloud storage
   - Migraci√≥n futura ser√° necesaria
   - No hay path directo de local a prod

5. **Backup Manual**
   - Debes recordar hacer backups
   - Proceso tedioso (rsync, cp a disco externo)
   - No hay snapshots autom√°ticos

### Implementaci√≥n

#### 1. Setup del Sistema de Archivos

```bash
# Crear estructura de directorios
mkdir -p ~/atlasfx-data/{raw,processed,features,models,experiments,backups}

# Crear subdirectorios para raw data
mkdir -p ~/atlasfx-data/raw/forex/{EURUSD,GBPUSD,USDJPY,AUDUSD,USDCAD,USDCHF,NZDUSD}
mkdir -p ~/atlasfx-data/raw/instruments/{XAUUSD,WTI,ES}

# Crear subdirectorios para processed data
mkdir -p ~/atlasfx-data/processed/{1min,5min,10min}

# Crear subdirectorios para features
mkdir -p ~/atlasfx-data/features/{train,val,test}
```

#### 2. Versionado Manual con Git Tags

```bash
# Despu√©s de generar features
cd ~/atlasfx-data/features

# Crear snapshot con hash
SNAPSHOT_HASH=$(find . -type f -exec md5sum {} + | sort | md5sum | cut -d' ' -f1)
echo $SNAPSHOT_HASH > VERSION.txt

# Tag en el repo de c√≥digo
cd ~/atlasfx-mvp
git tag -a "data-v1.0-${SNAPSHOT_HASH:0:8}" -m "Features for experiment v1.0"
git push --tags

# Documentar en experiment config
echo "data_version: v1.0-${SNAPSHOT_HASH:0:8}" >> configs/experiment.yaml
```

#### 3. Estrategia de Backup

**Opci√≥n A: Backup a Disco Externo (Semanal)**
```bash
#!/bin/bash
# backup_weekly.sh

SOURCE_DIR=~/atlasfx-data
BACKUP_DIR=/mnt/external-drive/atlasfx-backups
DATE=$(date +%Y-%m-%d)

# Crear backup con rsync
rsync -avh --progress \
  --exclude 'experiments/*' \
  --exclude '.cache/*' \
  $SOURCE_DIR/ $BACKUP_DIR/backup-$DATE/

# Mantener solo √∫ltimas 4 semanas
ls -t $BACKUP_DIR | tail -n +5 | xargs -I {} rm -rf $BACKUP_DIR/{}

echo "Backup completado: $BACKUP_DIR/backup-$DATE/"
```

**Opci√≥n B: Backup Selectivo (Solo Importantes)**
```bash
#!/bin/bash
# backup_important.sh

# Solo backupear datos cr√≠ticos (features y modelos)
IMPORTANT_DIRS=(
  "features"
  "models"
  "processed"  # Optional, se puede regenerar
)

for dir in "${IMPORTANT_DIRS[@]}"; do
  tar -czf ~/backups/atlasfx-${dir}-$(date +%Y%m%d).tar.gz \
    ~/atlasfx-data/$dir
done
```

#### 4. Reproducibilidad sin DVC

```python
# src/atlasfx/utils/versioning.py
import hashlib
import json
from pathlib import Path
from typing import Dict

class LocalDataVersioning:
    """Manual data versioning for local storage."""
    
    def __init__(self, data_dir: Path):
        self.data_dir = data_dir
        self.manifest_path = data_dir / "MANIFEST.json"
    
    def compute_hash(self, file_path: Path) -> str:
        """Compute MD5 hash of a file."""
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    
    def create_manifest(self) -> Dict[str, str]:
        """Create manifest with hashes of all files."""
        manifest = {}
        for file_path in self.data_dir.rglob("*.parquet"):
            rel_path = file_path.relative_to(self.data_dir)
            manifest[str(rel_path)] = self.compute_hash(file_path)
        
        # Save manifest
        with open(self.manifest_path, "w") as f:
            json.dump(manifest, f, indent=2)
        
        return manifest
    
    def verify_manifest(self) -> bool:
        """Verify data integrity against manifest."""
        if not self.manifest_path.exists():
            raise FileNotFoundError("Manifest not found")
        
        with open(self.manifest_path) as f:
            manifest = json.load(f)
        
        for rel_path, expected_hash in manifest.items():
            file_path = self.data_dir / rel_path
            if not file_path.exists():
                print(f"‚ùå Missing: {rel_path}")
                return False
            
            actual_hash = self.compute_hash(file_path)
            if actual_hash != expected_hash:
                print(f"‚ùå Corrupted: {rel_path}")
                return False
        
        print("‚úÖ All files verified")
        return True
```

#### 5. Uso en Experiments

```python
# scripts/train_vae.py
from atlasfx.utils.versioning import LocalDataVersioning
from pathlib import Path

# Verificar integridad de datos antes de entrenar
data_dir = Path("~/atlasfx-data/features").expanduser()
versioning = LocalDataVersioning(data_dir)

if versioning.manifest_path.exists():
    print("Verificando integridad de datos...")
    if not versioning.verify_manifest():
        raise ValueError("Data integrity check failed!")
else:
    print("Creando manifest de datos...")
    versioning.create_manifest()

# Proceder con entrenamiento
train_vae(data_dir)
```

### An√°lisis de Performance

#### SSD vs. HDD

**Para Raw Tick Data (100GB):**
- **HDD (7200 RPM):**
  - Sequential read: ~150 MB/s
  - Tiempo de carga: ~11 minutos
  - ‚úÖ Suficientemente r√°pido (loading se hace una vez)

- **SSD (SATA):**
  - Sequential read: ~500 MB/s
  - Tiempo de carga: ~3 minutos
  - ‚≠ê Ideal pero no cr√≠tico

- **NVMe SSD:**
  - Sequential read: ~3500 MB/s
  - Tiempo de carga: ~30 segundos
  - üöÄ Overkill para este proyecto

**Recomendaci√≥n:**
- **Raw data:** Puede estar en HDD (se accede raramente)
- **Processed features:** Mejor en SSD (acceso frecuente durante training)
- **Models & experiments:** SSD (I/O constante)

**Setup Ideal:**
```
HDD 1TB:
  ‚îî‚îÄ‚îÄ raw/          # Cold storage, acceso infrecuente

SSD 500GB:
  ‚îú‚îÄ‚îÄ processed/    # Warm storage
  ‚îú‚îÄ‚îÄ features/     # Hot storage
  ‚îú‚îÄ‚îÄ models/       # Hot storage
  ‚îî‚îÄ‚îÄ experiments/  # Hot storage
```

### Costo Estimado

**One-time:**
- SSD 500GB: $50-70 (si no tienes)
- Disco externo 1TB (backups): $50

**Mensual:**
- Electricidad: ~$2-3/mes (PC encendida 8h/d√≠a)
- **Total:** ~$2-3/mes

**Comparado con cloud:**
- DVC + S3: ~$7-10/mes
- **Ahorro:** ~$5-7/mes (~$60-84/a√±o)

### Recomendaci√≥n

‚≠ê‚≠ê‚≠ê‚≠ê **RECOMENDADO PARA MVP**

**Caso de Uso Ideal:**
- ‚úÖ Trabajo individual (no colaboraci√≥n)
- ‚úÖ Presupuesto cero para MVP
- ‚úÖ Datos se acceden una vez (pipeline) y luego poco
- ‚úÖ Tienes 1TB disponible (espacio suficiente)
- ‚úÖ Hardware ya disponible

**Por qu√© es ideal para tu caso:**

1. **Patr√≥n de Acceso:**
   - Raw data (100GB) se procesa UNA VEZ
   - Despu√©s solo accedes a features procesadas (~10GB)
   - 90% del espacio (raw data) queda en "cold storage"

2. **Capacidad Suficiente:**
   - 1TB >> 145GB necesarios (7x margen)
   - Espacio para crecer a 500+ features

3. **MVP Scope:**
   - No necesitas colaboraci√≥n a√∫n
   - Reproducibilidad manual es suficiente
   - Puedes migrar a cloud post-MVP

4. **Costo-Efectivo:**
   - $0/mes vs. $7-10/mes S3
   - Ahorro de $60-84/a√±o para MVP

**Cu√°ndo migrar a cloud:**
- Cuando empieces a colaborar con otros
- Cuando necesites acceder desde m√∫ltiples m√°quinas
- Cuando vayas a producci√≥n
- Cuando el costo de tu tiempo > $10/mes

---

## Opci√≥n 3: Git LFS (Large File Storage)

### Descripci√≥n

**Git LFS (Large File Storage)** es una extensi√≥n de Git que maneja archivos grandes. Los archivos grandes se almacenan en un servidor LFS (GitHub, GitLab, Bitbucket) y Git solo guarda punteros.

### Arquitectura Propuesta

```
Repository
‚îú‚îÄ‚îÄ data/                    # Git LFS tracked
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îî‚îÄ‚îÄ features/
‚îú‚îÄ‚îÄ models/                  # Git LFS tracked
‚îú‚îÄ‚îÄ .gitattributes           # LFS configuration
‚îî‚îÄ‚îÄ .git/
    ‚îî‚îÄ‚îÄ lfs/                 # LFS cache
```

### Ventajas ‚úÖ

1. **Simplicidad:**
   - Git workflow normal
   - No requiere setup de cloud
   - Una sola herramienta (Git)

2. **Integraci√≥n GitHub:**
   - Los datos viven en el mismo repo
   - Clone = c√≥digo + datos
   - F√°cil para colaboradores nuevos

3. **Costo Inicial Bajo:**
   - GitHub: 1GB gratis, $5/mes por 50GB
   - GitLab: 10GB gratis en plan free
   - Bitbucket: 1GB gratis

4. **Sin Dependencias Externas:**
   - No necesitas cuenta AWS/GCP
   - Todo en GitHub/GitLab
   - Menos servicios que administrar

### Desventajas ‚ùå

1. **Limitaciones de Tama√±o:**
   - GitHub LFS: L√≠mite de 2GB por archivo
   - 1GB de ancho de banda gratis/mes
   - Muy limitado para datos de trading (>100GB)

2. **Costo Escalable:**
   - GitHub: $5/mes por 50GB adicionales
   - Para 200GB: ~$20/mes (m√°s caro que S3)
   - Bandwidth charges pueden ser altos

3. **Performance:**
   - M√°s lento que S3 para archivos grandes
   - Clone inicial puede tardar horas
   - No optimizado para ML workloads

4. **No Es Verdadero Versionado:**
   - Git LFS puede tener conflictos
   - Eliminar versiones antiguas es complejo
   - No est√° dise√±ado para datasets grandes

5. **L√≠mites de GitHub:**
   - Repository size max: 100GB (recomendado <5GB)
   - Warnings despu√©s de 1GB
   - No escalable para producci√≥n

### Implementaci√≥n

```bash
# Instalar Git LFS
git lfs install

# Trackear archivos grandes
git lfs track "*.parquet"
git lfs track "*.h5"
git lfs track "*.pth"

# Agregar a Git
git add .gitattributes
git add data/raw/eurusd_2024.parquet
git commit -m "Add data with LFS"
git push
```

### Costo Estimado (Mensual)

- **Almacenamiento:** 120GB ‚Üí $15/mes (GitHub packs)
- **Bandwidth:** 50GB/mes ‚Üí $5/mes
- **Total:** ~$20/mes (m√°s caro que S3)

### Recomendaci√≥n

‚≠ê‚≠ê **NO RECOMENDADO PARA ESTE PROYECTO**

**Caso de Uso Ideal:**
- Proyectos peque√±os (<50GB)
- Equipos que solo usan GitHub
- Datos que cambian poco
- Prototipado r√°pido

**Por qu√© no para AtlasFX:**
- Los datos de tick superan los l√≠mites de GitHub LFS
- M√°s caro que S3 para vol√∫menes grandes
- No optimizado para ML workflows
- Escalabilidad limitada

---

## Opci√≥n 4: Base de Datos Especializada (TimescaleDB/InfluxDB)

### Descripci√≥n

Usar una **base de datos de series temporales** optimizada para datos financieros. TimescaleDB (PostgreSQL) o InfluxDB est√°n dise√±adas para manejar millones de ticks con queries eficientes.

### Arquitectura Propuesta

```
Database Server (Local o Cloud)
‚îî‚îÄ‚îÄ TimescaleDB
    ‚îú‚îÄ‚îÄ tick_data              # Raw ticks (hypertable)
    ‚îÇ   ‚îú‚îÄ‚îÄ timestamp
    ‚îÇ   ‚îú‚îÄ‚îÄ symbol
    ‚îÇ   ‚îú‚îÄ‚îÄ bid
    ‚îÇ   ‚îú‚îÄ‚îÄ ask
    ‚îÇ   ‚îî‚îÄ‚îÄ volume
    ‚îú‚îÄ‚îÄ aggregated_ohlc        # Pre-aggregated (hypertable)
    ‚îî‚îÄ‚îÄ features               # Processed features

Application Layer
‚îú‚îÄ‚îÄ data-pipeline/
‚îÇ   ‚îî‚îÄ‚îÄ db_loader.py          # ETL to database
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ data_loader.py        # Query features from DB
‚îî‚îÄ‚îÄ experiments/
    ‚îî‚îÄ‚îÄ mlflow/               # Model versioning with MLflow
```

### Ventajas ‚úÖ

1. **Performance Optimizado:**
   - Queries por rango temporal son ultra-r√°pidas
   - √çndices autom√°ticos en timestamp
   - Compresi√≥n de datos (TimescaleDB: 90%+ compression)
   - Agregaciones nativas (OHLC, VWAP)

2. **Queries SQL Potentes:**
   ```sql
   -- Obtener datos de entrenamiento
   SELECT * FROM features 
   WHERE timestamp BETWEEN '2024-01-01' AND '2024-06-30'
   AND symbol = 'EURUSD'
   ORDER BY timestamp;
   
   -- Calcular VWAP on-the-fly
   SELECT time_bucket('5 minutes', timestamp) AS bucket,
          symbol,
          SUM(price * volume) / SUM(volume) AS vwap
   FROM tick_data
   GROUP BY bucket, symbol;
   ```

3. **Versionado con Timestamps:**
   - Datos inmutables (insert-only)
   - Puedes recrear estado en cualquier momento
   - Auditor√≠a completa de cambios

4. **Escalabilidad Vertical:**
   - TimescaleDB escala a billones de filas
   - Puede manejar todo el hist√≥rico de Dukascopy
   - Particionamiento autom√°tico (time-based)

5. **Integraci√≥n Python:**
   - SQLAlchemy, pandas, psycopg2
   - Direct SQL queries desde PyTorch DataLoader
   - Streaming de datos para entrenamiento

6. **Costo-Efectivo (Local):**
   - PostgreSQL/TimescaleDB es open-source
   - Puedes correr en tu propia m√°quina
   - No hay costos de cloud (si es local)

### Desventajas ‚ö†Ô∏è

1. **Setup Complejo:**
   - Requiere administrar un servidor de BD
   - Configuraci√≥n de √≠ndices y particiones
   - Backups manuales necesarios

2. **No Es Versionado Nativo:**
   - No puedes volver a "versiones" como DVC
   - Necesitas snapshots manuales
   - Reproducibilidad requiere disciplina

3. **Backup Cr√≠tico:**
   - Si la BD se corrompe, pierdes todo
   - Necesitas estrategia de backup robusta
   - Disaster recovery m√°s complejo

4. **Memoria y Disco:**
   - Base de datos puede crecer mucho
   - Requiere SSD r√°pido para performance
   - Tuning de PostgreSQL necesario

5. **Limitaciones para ML:**
   - No integraci√≥n nativa con MLflow/W&B
   - Feature store requiere desarrollo custom
   - Versionado de features no es trivial

6. **Escalabilidad Horizontal Limitada:**
   - Scaling a m√∫ltiples m√°quinas es complejo
   - No es serverless (requiere servidor running)

### Implementaci√≥n

```python
# Conexi√≥n a TimescaleDB
import pandas as pd
from sqlalchemy import create_engine

engine = create_engine('postgresql://user:pass@localhost/atlasfx')

# Cargar tick data
df = pd.read_parquet('eurusd_ticks.parquet')
df.to_sql('tick_data', engine, if_exists='append', index=False)

# Query para entrenamiento
query = """
SELECT * FROM features 
WHERE timestamp >= '2024-01-01'::timestamp
AND timestamp < '2024-07-01'::timestamp
ORDER BY timestamp
"""
train_data = pd.read_sql(query, engine)

# Crear hypertable (TimescaleDB)
engine.execute("""
    SELECT create_hypertable('tick_data', 'timestamp',
                             chunk_time_interval => INTERVAL '1 day');
""")
```

### Costo Estimado (Mensual)

**Opci√≥n Local:**
- Hardware: $0 (usa tu m√°quina)
- Almacenamiento: SSD de 512GB (~$50 one-time)
- Electricidad: ~$5/mes
- **Total:** ~$5/mes

**Opci√≥n Cloud (TimescaleDB Cloud):**
- Starter: $50/mes (25GB storage, 0.5 CPU)
- Growth: $200/mes (100GB storage, 2 CPU)
- **Total:** $50-200/mes (muy caro para MVP)

### Recomendaci√≥n

‚≠ê‚≠ê‚≠ê **RECOMENDADO PARA CIERTOS CASOS**

**Caso de Uso Ideal:**
- Sistemas de trading en producci√≥n (latencia cr√≠tica)
- Necesitas queries complejas sobre ticks
- Acceso en tiempo real a datos hist√≥ricos
- Infraestructura local (no cloud)

**Por qu√© podr√≠a no ser ideal para AtlasFX MVP:**
- Complejidad de setup vs. DVC
- No tiene versionado nativo de datasets
- Backup y disaster recovery m√°s dif√≠cil
- Mejor para producci√≥n que para investigaci√≥n

**Cu√°ndo considerarlo:**
- Despu√©s del MVP, para deployment
- Si necesitas backtesting ultra-r√°pido
- Si tienes experiencia con bases de datos

---

## Comparaci√≥n Final

| Criterio | DVC + S3/GCS | Local Puro | Git LFS | TimescaleDB |
|----------|-------------|------------|---------|-------------|
| **Costo (MVP)** | $7-10/mes | $2-3/mes | $20/mes | $5/mes (local) |
| **Escalabilidad** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excelente | ‚≠ê‚≠ê Limitada | ‚≠ê‚≠ê Limitada | ‚≠ê‚≠ê‚≠ê‚≠ê Muy buena |
| **Versionado** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Nativo | ‚≠ê‚≠ê Manual | ‚≠ê‚≠ê‚≠ê B√°sico | ‚≠ê‚≠ê Manual |
| **Performance** | ‚≠ê‚≠ê‚≠ê‚≠ê Muy bueno | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excelente | ‚≠ê‚≠ê‚≠ê Bueno | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excelente |
| **Facilidad Setup** | ‚≠ê‚≠ê‚≠ê‚≠ê F√°cil | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Muy f√°cil | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Muy f√°cil | ‚≠ê‚≠ê Complejo |
| **Reproducibilidad** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Perfecta | ‚≠ê‚≠ê‚≠ê Requiere disciplina | ‚≠ê‚≠ê‚≠ê Buena | ‚≠ê‚≠ê‚≠ê Requiere disciplina |
| **Colaboraci√≥n** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excelente | ‚≠ê Limitada | ‚≠ê‚≠ê‚≠ê‚≠ê Buena | ‚≠ê‚≠ê Media |
| **ML Ecosystem** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Perfecto | ‚≠ê‚≠ê‚≠ê Aceptable | ‚≠ê‚≠ê‚≠ê Aceptable | ‚≠ê‚≠ê‚≠ê Custom integration |
| **Backup** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Autom√°tico | ‚≠ê‚≠ê Manual | ‚≠ê‚≠ê‚≠ê‚≠ê Incluido | ‚≠ê‚≠ê Manual |
| **Complejidad** | ‚≠ê‚≠ê‚≠ê Media | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Muy baja | ‚≠ê‚≠ê‚≠ê‚≠ê Baja | ‚≠ê‚≠ê Alta |
| **Acceso Infrec.** | ‚≠ê‚≠ê‚≠ê OK (latencia) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Perfecto | ‚≠ê‚≠ê‚≠ê OK | ‚≠ê‚≠ê‚≠ê‚≠ê Muy bueno |

---

## Recomendaci√≥n Final

### Para MVP: Dos Opciones V√°lidas

Dependiendo de tus prioridades, hay **dos opciones recomendadas** para el MVP:

---

### ü•á **Opci√≥n A: Almacenamiento Local Puro (Recomendado para MVP)**

#### Justificaci√≥n

Para el **MVP de AtlasFX**, **almacenamiento local** es la mejor opci√≥n inicial porque:

1. **Patr√≥n de Acceso Ideal:**
   - Raw data (100GB) se procesa **UNA VEZ** durante el pipeline
   - Despu√©s solo accedes a features procesadas (~10GB)
   - 90% del espacio queda en "cold storage" (no se usa frecuentemente)
   - Cita del problema statement: *"no es que los tengamos que usar constantemente ya que una vez que generemos el df del data pipeline ya no creo que los usemos mucho"*

2. **Capacidad M√°s que Suficiente:**
   - 1TB disponible >> 145GB necesarios (factor 7x)
   - Espacio para crecer features de 200 a 500+ sin problemas
   - Margen para experimentos, checkpoints, logs

3. **Costo Cero:**
   - No hay costos mensuales ($0 vs. $7-10/mes S3)
   - Hardware ya disponible
   - Ahorro de ~$60-84/a√±o durante desarrollo MVP

4. **Simplicidad:**
   - No requiere setup de DVC, AWS, credenciales
   - File system normal (cp, mv, rsync)
   - Menos moving parts = menos cosas que romper
   - M√°s tiempo para enfocarte en algoritmos

5. **Performance Excelente:**
   - Latencia ultra-baja (I/O local)
   - No dependes de internet
   - Especialmente con SSD para features/models

6. **Viable para el Alcance del MVP:**
   - Trabajo individual (sin colaboraci√≥n a√∫n)
   - Reproducibilidad manual es suficiente
   - Path de migraci√≥n claro a cloud post-MVP

#### Implementaci√≥n Recomendada (MVP)

```bash
# Setup estructura local
~/atlasfx-data/
‚îú‚îÄ‚îÄ raw/              # 100GB - HDD OK (cold storage)
‚îú‚îÄ‚îÄ processed/        # 10-20GB - SSD recomendado
‚îú‚îÄ‚îÄ features/         # 5-10GB - SSD recomendado
‚îú‚îÄ‚îÄ models/           # 5GB - SSD recomendado
‚îî‚îÄ‚îÄ experiments/      # 10GB - SSD recomendado

# Versionado manual con manifests
python scripts/create_data_manifest.py

# Backup semanal a disco externo
rsync -avh ~/atlasfx-data/ /mnt/external/atlasfx-backups/
```

#### Cu√°ndo Migrar a Cloud

Migrar a **DVC + S3** cuando:
- ‚úÖ MVP completado y validado
- ‚úÖ Necesites colaborar con otros
- ‚úÖ Trabajes desde m√∫ltiples m√°quinas
- ‚úÖ Vayas a producci√≥n
- ‚úÖ Tu tiempo vale m√°s que $10/mes

---

### ü•à **Opci√≥n B: DVC + AWS S3 (Alternativa Profesional)**

#### Justificaci√≥n

Si prefieres setup m√°s profesional desde el inicio, **DVC + S3** sigue siendo excelente porque:

1. **Versionado Autom√°tico:**
   - Cada versi√≥n de datos tiene hash √∫nico
   - Puedes volver a cualquier versi√≥n hist√≥rica
   - Reproducibilidad perfecta sin esfuerzo manual

2. **Est√°ndares de ML Research:**
   - Integraci√≥n nativa con MLflow, W&B
   - Compatible con PyTorch DataLoaders
   - Usado por proyectos de nivel doctoral

3. **Escalabilidad:**
   - De MVP a producci√≥n sin cambios de arquitectura
   - S3 puede manejar petabytes si es necesario
   - Alta disponibilidad y durabilidad (99.999999999%)

4. **Backup Autom√°tico:**
   - Datos replicados autom√°ticamente
   - No dependes de una sola m√°quina
   - Disaster recovery incluido

5. **Bajo Riesgo:**
   - P√©rdida de datos es pr√°cticamente imposible
   - No preocuparte por backups manuales

#### Costo Estimado

- **MVP (primeros 6 meses):** ~$50-60 ($7-10/mes)
- **Post-MVP (a√±o 1):** ~$100-200/a√±o

#### Implementaci√≥n Recomendada

```bash
# Semana 1: Setup DVC
pip install dvc[s3]
dvc init
dvc remote add -d storage s3://atlasfx-mvp-data/dvc-store

# Semana 2: Migrar datos existentes
dvc add data/raw/
dvc add data/processed/
dvc push
git commit -m "Add data versioning with DVC"

# Workflow normal
python data-pipeline/pipeline.py
dvc add data/features/v1.0.parquet
git add data/features/v1.0.parquet.dvc
git commit -m "Add features v1.0"
dvc push
```

---

### üéØ **Recomendaci√≥n Personalizada para Tu Caso**

Basado en la informaci√≥n del problema statement:

**‚úÖ USAR ALMACENAMIENTO LOCAL PURO PARA MVP**

**Razones espec√≠ficas para tu caso:**

1. **Tienes hardware adecuado:**
   - 1TB exclusivo para proyecto ‚úÖ
   - Suficiente para 100GB raw + expansi√≥n

2. **Patr√≥n de acceso confirma viabilidad:**
   - Raw data se usa una vez (pipeline) ‚úÖ
   - Despu√©s acceso m√≠nimo ‚úÖ
   - No justifica costos de cloud

3. **Alcance del MVP:**
   - Trabajo individual (sin colaboraci√≥n) ‚úÖ
   - Presupuesto limitado ‚úÖ
   - Foco en algoritmos, no infraestructura

4. **Path de migraci√≥n claro:**
   - Empiezas local (r√°pido, barato)
   - Migras a DVC + S3 post-MVP si necesario
   - No pierdes tiempo/dinero en setup prematuro

**Plan de Implementaci√≥n:**

```
MVP (Semanas 1-18):
  ‚úÖ Almacenamiento local puro
  ‚úÖ Versionado manual con manifests
  ‚úÖ Backups semanales a disco externo
  
Post-MVP (Semanas 19+):
  Evaluar si migrar a DVC + S3 basado en:
    - ¬øNecesitas colaboraci√≥n?
    - ¬øM√∫ltiples m√°quinas?
    - ¬øProducci√≥n?
    
  Si respuesta es NO ‚Üí Mantener local
  Si respuesta es S√ç ‚Üí Migrar a DVC + S3
```

---

### Arquitectura H√≠brida (Futuro Post-MVP)

Cuando el proyecto pase a producci√≥n, la mejor estrategia es **h√≠brida**:

1. **Mantener Local para:**
   - Desarrollo e iteraci√≥n r√°pida
   - Experiments que requieren I/O intensivo
   - Cache de datos frecuentemente usados

2. **Usar DVC + S3 para:**
   - Versionado de datasets de entrenamiento
   - Compartir datos con colaboradores
   - Backup y disaster recovery
   - Reproducibilidad cient√≠fica

3. **Agregar TimescaleDB para:**
   - Datos en tiempo real (tick stream en producci√≥n)
   - Queries de backtesting r√°pidos
   - Monitoreo de performance en vivo

**Arquitectura H√≠brida:**
```
Research/Training:
  ‚îú‚îÄ‚îÄ Local SSD (hot data, fast iteration)
  ‚îî‚îÄ‚îÄ DVC + S3 (versioning, backup, sharing)

Production/Live:
  ‚îú‚îÄ‚îÄ TimescaleDB (real-time ticks, low latency)
  ‚îî‚îÄ‚îÄ S3 (backup, archival)

Archival:
  ‚îî‚îÄ‚îÄ S3 Glacier (cold storage, old experiments)
```

---

### Resumen de Decisi√≥n

| Fase | Recomendaci√≥n | Raz√≥n |
|------|--------------|-------|
| **MVP (ahora)** | üèÜ **Local Puro** | Costo $0, simplicidad, hardware disponible, patr√≥n de acceso ideal |
| **Post-MVP** | Evaluar migraci√≥n a DVC + S3 | Si necesitas colaboraci√≥n, reproducibilidad avanzada |
| **Producci√≥n** | H√≠brido (Local + DVC + TimescaleDB) | Mejor de todos los mundos |

---

### Alternativa Econ√≥mica (Si Prefieres Cloud desde el Inicio)

Si quieres empezar con cloud pero presupuesto es limitado:

**Opci√≥n Intermedia: DVC + Google Drive**
- Google Drive: 15GB gratis (suficiente para features procesadas)
- DVC soporta Google Drive como remote
- Mant√©n raw data local (100GB)
- Versionas solo datos procesados (~10GB)

```bash
# Setup DVC con Google Drive
pip install dvc[gdrive]
dvc remote add -d storage gdrive://folder-id
dvc remote modify storage gdrive_acknowledge_abuse true

# Solo versionar features, no raw data
dvc add data/features/
dvc push
```

**Costo:** $0/mes (hasta 15GB)

---

## Conclusi√≥n

**Para AtlasFX MVP, la recomendaci√≥n es:**

### ‚úÖ Implementar: Almacenamiento Local Puro

**Razones:**
- Hardware disponible (1TB) ‚úÖ
- Patr√≥n de acceso ideal (una vez) ‚úÖ
- Costo $0 vs. $7-10/mes ‚úÖ
- Simplicidad m√°xima ‚úÖ
- Performance excelente ‚úÖ
- Path de migraci√≥n claro ‚úÖ

**Next Steps:**
1. Crear estructura de directorios local
2. Implementar sistema de manifests para versioning manual
3. Setup script de backup autom√°tico (semanal)
4. Documentar convenciones de naming/versioning
5. Proceder con desarrollo del MVP

**Migraci√≥n Futura (Post-MVP):**
- Evaluar necesidad basada en colaboraci√≥n/producci√≥n
- Si necesario, migrar a DVC + S3
- Proceso de migraci√≥n es straightforward (DVC facilita)

---

### üìä Comparaci√≥n Costo Total (3 a√±os)

| Opci√≥n | Setup | A√±o 1 | A√±o 2 | A√±o 3 | Total 3 a√±os |
|--------|-------|-------|-------|-------|--------------|
| **Local Puro** | $100 (SSD+backup disk) | $30 | $30 | $30 | **$190** |
| **DVC + S3** | $0 | $120 | $150 | $200 | **$470** |
| **Git LFS** | $0 | $240 | $300 | $360 | **$900** |
| **TimescaleDB Cloud** | $0 | $600 | $2400 | $2400 | **$5400** |

**Ahorro de Local vs. DVC:** $280 en 3 a√±os  
**Ahorro de Local vs. Git LFS:** $710 en 3 a√±os

**ROI:** Para MVP, el ahorro de $280 es significativo. Post-MVP, cuando generes value, $10/mes de S3 es despreciable.

---

**Autor:** An√°lisis actualizado para AtlasFX MVP  
**Fecha:** 20 de Octubre, 2025  
**Versi√≥n:** 2.0 (incluye an√°lisis de almacenamiento local)

---

**Autor:** An√°lisis actualizado para AtlasFX MVP  
**Fecha:** 20 de Octubre, 2025  
**Versi√≥n:** 2.0 (incluye an√°lisis de almacenamiento local)
