# AtlasFX - AnÃ¡lisis de Estructura del Repositorio

**VersiÃ³n:** 1.0  
**Fecha:** 20 de Octubre, 2025  
**PropÃ³sito:** Evaluar la estructura ideal del repositorio y decidir si conviene adoptar la estructura propuesta

---

## Executive Summary

Este documento evalÃºa dos estructuras de repositorio:
1. **Estructura Actual** (post-cleanup, orientada a MVP)
2. **Estructura Propuesta** (tu documentaciÃ³n guardada)

**RecomendaciÃ³n:** âœ… **Adoptar estructura propuesta con modificaciones incrementales**

La estructura propuesta es mÃ¡s profesional, escalable y alineada con estÃ¡ndares de proyectos ML en producciÃ³n. Sin embargo, se recomienda migrar de forma **incremental** durante las fases del MVP en vez de hacerlo todo de una vez.

---

## Estructura Actual (Post-Cleanup)

```
atlasfx-mvp/
â”œâ”€â”€ data-pipeline/              # Pipeline de procesamiento de datos
â”‚   â”œâ”€â”€ pipeline.py            # OrquestaciÃ³n
â”‚   â”œâ”€â”€ merge.py               # Merging de ticks
â”‚   â”œâ”€â”€ clean.py               # Limpieza
â”‚   â”œâ”€â”€ aggregate.py           # AgregaciÃ³n temporal
â”‚   â”œâ”€â”€ featurize.py           # Feature engineering
â”‚   â”œâ”€â”€ featurizers.py         # Calculadores de features
â”‚   â”œâ”€â”€ aggregators.py         # Funciones de agregaciÃ³n
â”‚   â”œâ”€â”€ normalize.py           # NormalizaciÃ³n
â”‚   â”œâ”€â”€ split.py               # Train/val/test split
â”‚   â”œâ”€â”€ winsorize.py           # Manejo de outliers
â”‚   â”œâ”€â”€ visualize.py           # VisualizaciÃ³n
â”‚   â”œâ”€â”€ logger.py              # Logging
â”‚   â”œâ”€â”€ pipeline.yaml          # ConfiguraciÃ³n
â”‚   â””â”€â”€ requirements.txt       # Dependencias
â”œâ”€â”€ docs/                       # DocumentaciÃ³n
â”‚   â”œâ”€â”€ ARCHITECTURE.md
â”‚   â”œâ”€â”€ AUDIT_REPORT.md
â”‚   â”œâ”€â”€ FEATURES.md
â”‚   â”œâ”€â”€ MVP_ACTION_PLAN.md
â”‚   â”œâ”€â”€ NEXT_STEPS.md
â”‚   â”œâ”€â”€ DONDE_ALMACENAR_DATOS.md
â”‚   â””â”€â”€ BACKLOG.md            # âœ… Nuevo
â”œâ”€â”€ tests/                      # Tests
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ conftest.py
â”œâ”€â”€ README.md
â”œâ”€â”€ REFACTORING_SUMMARY.md
â””â”€â”€ pyproject.toml
```

### Fortalezas âœ…

1. **Simple y Enfocado**
   - Todo relacionado con el pipeline estÃ¡ en un lugar
   - FÃ¡cil de navegar para el MVP
   - Bajo overhead de estructura

2. **DocumentaciÃ³n Completa**
   - Carpeta `docs/` bien organizada
   - Decision records claros

3. **Testing Infrastructure**
   - Tests separados por tipo (unit/integration)
   - Fixtures compartidas en conftest.py

### Debilidades âš ï¸

1. **No Escalable**
   - `data-pipeline/` va a crecer mucho cuando agreguemos VAE, TFT, SAC
   - Todo mezclado en raÃ­z (no hay separaciÃ³n clara)

2. **No Es un Paquete Instalable**
   - No hay `src/atlasfx/` â†’ No puedes hacer `pip install .`
   - Dificulta imports relativos
   - No puedes instalar en otro proyecto

3. **Falta ModularizaciÃ³n**
   - No hay separaciÃ³n entre:
     - Data loading
     - Model training
     - Model evaluation
     - Deployment/Execution

4. **No Sigue PEP Standards**
   - PEP 517/518 recomienda `src/` layout
   - Protege contra accidental imports de tests

---

## Estructura Propuesta (De Tu DocumentaciÃ³n)

```
atlasfx/
â”œâ”€â”€ atlasfx/                    # Paquete principal
â”‚   â”œâ”€â”€ data/                  # MÃ³dulo de gestiÃ³n de datos
â”‚   â”‚   â”œâ”€â”€ loader.py          # Carga de datos desde mÃºltiples formatos
â”‚   â”‚   â”œâ”€â”€ preprocessor.py    # Preprocesamiento de datos
â”‚   â”‚   â””â”€â”€ validator.py       # ValidaciÃ³n de datos de tick
â”‚   â”œâ”€â”€ models/                # MÃ³dulo de modelos
â”‚   â”‚   â”œâ”€â”€ base.py            # Clase base para modelos
â”‚   â”‚   â””â”€â”€ ml_model.py        # Modelo de ML (Random Forest)
â”‚   â”œâ”€â”€ training/              # MÃ³dulo de entrenamiento
â”‚   â”‚   â””â”€â”€ trainer.py         # Entrenador de modelos
â”‚   â”œâ”€â”€ evaluation/            # MÃ³dulo de evaluaciÃ³n
â”‚   â”‚   â”œâ”€â”€ evaluator.py       # Evaluador de modelos
â”‚   â”‚   â””â”€â”€ metrics.py         # MÃ©tricas de trading
â”‚   â””â”€â”€ execution/             # MÃ³dulo de ejecuciÃ³n
â”‚       â””â”€â”€ executor.py        # Ejecutor de estrategias
â”œâ”€â”€ tests/                     # Tests unitarios
â”œâ”€â”€ config/                    # Archivos de configuraciÃ³n
â”œâ”€â”€ schemas/                   # Esquemas de datos (YAML)
â”œâ”€â”€ data/                      # Directorio de datos (no versionado)
â”œâ”€â”€ models/                    # Modelos guardados (no versionado)
â””â”€â”€ pyproject.toml            # ConfiguraciÃ³n del proyecto
```

### AnÃ¡lisis de la Propuesta

#### Fortalezas âœ…

1. **Modular y Organizado**
   - SeparaciÃ³n clara por responsabilidad
   - Cada mÃ³dulo tiene un propÃ³sito Ãºnico

2. **Escalable**
   - FÃ¡cil agregar nuevos modelos en `models/`
   - FÃ¡cil agregar nuevas mÃ©tricas en `evaluation/`

3. **Profesional**
   - Sigue convenciones de proyectos ML
   - Similar a scikit-learn, PyTorch Lightning, etc.

4. **Instalable**
   - Puedes hacer `pip install -e .`
   - Imports limpios: `from atlasfx.models import VAE`

#### Debilidades âš ï¸

1. **AmbigÃ¼edad en Nombres**
   - `ml_model.py` es genÃ©rico (Â¿quÃ© modelo?)
   - `executor.py` podrÃ­a confundirse con execution de cÃ³digo

2. **Falta de Contexto**
   - No menciona dÃ³nde van scripts de entrenamiento
   - No menciona notebooks exploratorios
   - No menciona experiments/logs

3. **Muy GenÃ©rica**
   - DiseÃ±ada para cualquier proyecto ML
   - No especÃ­fica para trading/RL/time-series

---

## Estructura Recomendada (HÃ­brida Optimizada)

Combinando lo mejor de ambas + mejores prÃ¡cticas de la industria:

```
atlasfx-mvp/
â”œâ”€â”€ src/                           # Source code (PEP 517/518 layout)
â”‚   â””â”€â”€ atlasfx/                  # Paquete principal instalable
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ data/                 # MÃ³dulo de gestiÃ³n de datos
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ loaders.py        # Carga desde Parquet, CSV, DVC
â”‚       â”‚   â”œâ”€â”€ processors.py     # Merge, clean, aggregate
â”‚       â”‚   â”œâ”€â”€ validators.py     # ValidaciÃ³n de tick data
â”‚       â”‚   â”œâ”€â”€ featurizers.py    # Feature engineering
â”‚       â”‚   â””â”€â”€ splitters.py      # Train/val/test splits
â”‚       â”œâ”€â”€ models/               # MÃ³dulo de modelos DL
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ base.py           # Clase base AbstractModel
â”‚       â”‚   â”œâ”€â”€ vae.py            # Variational Autoencoder
â”‚       â”‚   â”œâ”€â”€ tft.py            # Temporal Fusion Transformer
â”‚       â”‚   â””â”€â”€ sac.py            # Soft Actor-Critic agent
â”‚       â”œâ”€â”€ training/             # MÃ³dulo de entrenamiento
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ trainers.py       # Trainer genÃ©rico
â”‚       â”‚   â”œâ”€â”€ vae_trainer.py    # VAE-specific trainer
â”‚       â”‚   â”œâ”€â”€ tft_trainer.py    # TFT-specific trainer
â”‚       â”‚   â””â”€â”€ sac_trainer.py    # SAC-specific trainer
â”‚       â”œâ”€â”€ evaluation/           # MÃ³dulo de evaluaciÃ³n
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ metrics.py        # Sharpe, drawdown, win rate
â”‚       â”‚   â”œâ”€â”€ backtester.py     # Backtesting engine
â”‚       â”‚   â””â”€â”€ visualizers.py    # Plots y reportes
â”‚       â”œâ”€â”€ environments/         # Trading environments (Gym)
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ trading_env.py    # Main trading environment
â”‚       â”‚   â””â”€â”€ rewards.py        # Reward functions
â”‚       â”œâ”€â”€ agents/               # RL agent wrappers
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ sac_agent.py      # SAC wrapper para deployment
â”‚       â”œâ”€â”€ utils/                # Utilidades compartidas
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ logging.py        # Logging utilities
â”‚       â”‚   â”œâ”€â”€ reproducibility.py # Seed fixing
â”‚       â”‚   â””â”€â”€ io.py             # File I/O helpers
â”‚       â””â”€â”€ config/               # Configuration schemas
â”‚           â”œâ”€â”€ __init__.py
â”‚           â””â”€â”€ schemas.py        # Pydantic configs
â”œâ”€â”€ tests/                         # Tests (mirrors src/ structure)
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ evaluation/
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ test_data_pipeline.py
â”‚   â”‚   â””â”€â”€ test_training_loop.py
â”‚   â””â”€â”€ conftest.py               # Shared fixtures
â”œâ”€â”€ scripts/                       # Scripts ejecutables
â”‚   â”œâ”€â”€ run_data_pipeline.py      # Ejecutar pipeline de datos
â”‚   â”œâ”€â”€ train_vae.py              # Entrenar VAE
â”‚   â”œâ”€â”€ train_tft.py              # Entrenar TFT
â”‚   â”œâ”€â”€ train_sac.py              # Entrenar SAC agent
â”‚   â”œâ”€â”€ backtest.py               # Backtesting
â”‚   â””â”€â”€ deploy.py                 # Deployment a producciÃ³n
â”œâ”€â”€ notebooks/                     # Jupyter notebooks (exploratory)
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_feature_analysis.ipynb
â”‚   â””â”€â”€ 03_model_debugging.ipynb
â”œâ”€â”€ configs/                       # Archivos de configuraciÃ³n YAML
â”‚   â”œâ”€â”€ data_pipeline.yaml
â”‚   â”œâ”€â”€ vae.yaml
â”‚   â”œâ”€â”€ tft.yaml
â”‚   â””â”€â”€ sac.yaml
â”œâ”€â”€ experiments/                   # MLflow / W&B logs
â”‚   â””â”€â”€ .gitkeep
â”œâ”€â”€ data/                          # Datos (DVC tracked)
â”‚   â”œâ”€â”€ raw/                      # Raw tick data
â”‚   â”œâ”€â”€ processed/                # Cleaned & aggregated
â”‚   â”œâ”€â”€ features/                 # Feature matrices
â”‚   â””â”€â”€ splits/                   # Train/val/test
â”œâ”€â”€ models/                        # Modelos guardados (.pth)
â”‚   â”œâ”€â”€ vae/
â”‚   â”œâ”€â”€ tft/
â”‚   â””â”€â”€ sac/
â”œâ”€â”€ docs/                          # DocumentaciÃ³n
â”‚   â”œâ”€â”€ ARCHITECTURE.md
â”‚   â”œâ”€â”€ FEATURES.md
â”‚   â”œâ”€â”€ MVP_ACTION_PLAN.md
â”‚   â”œâ”€â”€ DONDE_ALMACENAR_DATOS.md
â”‚   â”œâ”€â”€ BACKLOG.md               # âœ… Nuevo
â”‚   â”œâ”€â”€ REPOSITORY_STRUCTURE.md  # âœ… Este documento
â”‚   â””â”€â”€ api/                      # Sphinx API docs (auto-generated)
â”œâ”€â”€ .github/                       # GitHub workflows
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml                # CI/CD pipeline
â”‚       â””â”€â”€ deploy.yml            # Deployment workflow
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .pre-commit-config.yaml       # Pre-commit hooks
â”œâ”€â”€ pyproject.toml                # Poetry config + tool configs
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## JustificaciÃ³n de la Estructura Recomendada

### 1. `src/atlasfx/` Layout (PEP 517/518)

**Por quÃ©:**
- Evita accidental imports de root
- Fuerza a instalar el paquete (`pip install -e .`)
- Protege contra import conflicts
- Permite imports limpios: `from atlasfx.models import VAE`

**Referencia:** [Python Packaging Guide - src layout](https://packaging.python.org/en/latest/discussions/src-layout-vs-flat-layout/)

---

### 2. SeparaciÃ³n `data/` vs. `models/` vs. `training/` vs. `evaluation/`

**Por quÃ©:**
- **Single Responsibility Principle:** Cada mÃ³dulo hace una cosa
- **Reusabilidad:** `models/` puede usarse sin `training/`
- **Testing:** Tests mÃ¡s focalizados y rÃ¡pidos
- **ColaboraciÃ³n:** Equipos pueden trabajar en mÃ³dulos diferentes

**Ejemplo:**
```python
# Limpio y modular
from atlasfx.data import load_tick_data, preprocess
from atlasfx.models import VAE
from atlasfx.training import VAETrainer

# vs. estructura actual (todo mezclado)
from data_pipeline.featurize import featurize  # Â¿DÃ³nde estÃ¡ VAE?
```

---

### 3. `scripts/` para Entry Points

**Por quÃ©:**
- Separa lÃ³gica (en `src/`) de ejecuciÃ³n (en `scripts/`)
- Scripts son simples: parsean args, llaman a funciones
- LÃ³gica compleja vive en `src/` y estÃ¡ testeada

**Ejemplo:**
```python
# scripts/train_vae.py
from atlasfx.training import VAETrainer
from atlasfx.config import VAEConfig

def main():
    config = VAEConfig.from_yaml("configs/vae.yaml")
    trainer = VAETrainer(config)
    trainer.train()

if __name__ == "__main__":
    main()
```

---

### 4. `configs/` Separado

**Por quÃ©:**
- Configs son "datos" no cÃ³digo
- FÃ¡cil versionar diferentes experimentos
- No mezclados con cÃ³digo

**Estructura:**
```yaml
# configs/vae.yaml
model:
  input_dim: 200
  latent_dim: 64
  hidden_dims: [128, 64]
  beta: 1.0

training:
  learning_rate: 0.001
  batch_size: 256
  epochs: 100
```

---

### 5. `notebooks/` para ExploraciÃ³n

**Por quÃ©:**
- Notebooks son para anÃ¡lisis exploratorio
- No son parte del cÃ³digo productivo
- Gitignore outputs, versionar solo `.ipynb`

**ConvenciÃ³n:**
- Nombres con prefijo numÃ©rico: `01_`, `02_`, etc.
- Documentar propÃ³sito en primera celda

---

### 6. `experiments/` para MLflow/W&B

**Por quÃ©:**
- Logs de experimentos separados del cÃ³digo
- Gitignore esta carpeta (muy grande)
- Solo versionar configs y resultados finales

---

### 7. `tests/` que Espeja `src/`

**Por quÃ©:**
- FÃ¡cil encontrar tests de un mÃ³dulo
- Estructura clara: `tests/unit/data/test_loaders.py` â†” `src/atlasfx/data/loaders.py`

---

## Plan de MigraciÃ³n Incremental

### Fase 1: Setup BÃ¡sico (Semana 1-2 del MVP)
```bash
# Crear estructura base
mkdir -p src/atlasfx/{data,models,training,evaluation,environments,agents,utils,config}
mkdir -p scripts configs notebooks experiments

# Mover pyproject.toml config
# Configurar Poetry con src/ layout
```

**Deliverables:**
- [ ] Estructura de carpetas creada
- [ ] `pyproject.toml` actualizado
- [ ] `src/atlasfx/__init__.py` creado

---

### Fase 2: Migrar Data Pipeline (Semana 3-4 del MVP)
```bash
# Mover mÃ³dulos de data-pipeline/ a src/atlasfx/data/
mv data-pipeline/merge.py src/atlasfx/data/loaders.py  # refactor
mv data-pipeline/clean.py src/atlasfx/data/processors.py  # refactor
mv data-pipeline/featurize.py src/atlasfx/data/featurizers.py
# ... etc
```

**Deliverables:**
- [ ] Todo en `data-pipeline/` migrado a `src/atlasfx/data/`
- [ ] Imports actualizados
- [ ] Tests actualizados
- [ ] Script `scripts/run_data_pipeline.py` creado

---

### Fase 3: Agregar Modelos (Semana 5-8 del MVP)
```bash
# Implementar VAE y TFT
touch src/atlasfx/models/{base.py,vae.py,tft.py}
touch src/atlasfx/training/{trainers.py,vae_trainer.py,tft_trainer.py}
```

**Deliverables:**
- [ ] VAE implementado en `src/atlasfx/models/vae.py`
- [ ] TFT implementado en `src/atlasfx/models/tft.py`
- [ ] Trainers implementados
- [ ] Scripts de entrenamiento en `scripts/`

---

### Fase 4: Agregar SAC y Environment (Semana 9-10 del MVP)
```bash
touch src/atlasfx/models/sac.py
touch src/atlasfx/environments/trading_env.py
touch src/atlasfx/agents/sac_agent.py
```

**Deliverables:**
- [ ] SAC implementado
- [ ] Trading environment implementado
- [ ] Agent wrapper implementado
- [ ] Script de entrenamiento SAC

---

### Fase 5: Evaluation & Backtesting (Semana 11-12 del MVP)
```bash
touch src/atlasfx/evaluation/{metrics.py,backtester.py,visualizers.py}
touch scripts/backtest.py
```

**Deliverables:**
- [ ] MÃ©tricas implementadas
- [ ] Backtester implementado
- [ ] Visualizaciones implementadas
- [ ] Script de backtesting

---

## ComparaciÃ³n Final

| Aspecto | Actual | Propuesta Original | Recomendada |
|---------|--------|-------------------|-------------|
| **Modularidad** | â­â­ Baja | â­â­â­â­ Alta | â­â­â­â­â­ Muy Alta |
| **Escalabilidad** | â­â­ Limitada | â­â­â­â­ Buena | â­â­â­â­â­ Excelente |
| **Instalabilidad** | âŒ No | âœ… SÃ­ | âœ… SÃ­ |
| **Standards** | â­â­ Parcial | â­â­â­ Bueno | â­â­â­â­â­ PEP compliant |
| **Claridad** | â­â­â­ OK | â­â­â­â­ Buena | â­â­â­â­â­ Muy Clara |
| **Testing** | â­â­â­ BÃ¡sico | â­â­â­ BÃ¡sico | â­â­â­â­â­ Estructurado |
| **DocumentaciÃ³n** | â­â­â­â­ Muy Buena | â­â­ Limitada | â­â­â­â­â­ Completa |
| **Complejidad Inicial** | â­â­â­â­â­ Simple | â­â­â­ Media | â­â­â­ Media |

---

## RecomendaciÃ³n Final

### âœ… ADOPTAR ESTRUCTURA RECOMENDADA

**Razones:**

1. **Profesionalismo:**
   - Sigue estÃ¡ndares de industria (PEP 517/518)
   - Similar a proyectos open-source exitosos

2. **Escalabilidad:**
   - FÃ¡cil agregar nuevos modelos, agentes, metrics
   - No requiere reestructurar al escalar

3. **ColaboraciÃ³n:**
   - Estructura clara facilita onboarding
   - SeparaciÃ³n de responsabilidades

4. **Mantenibilidad:**
   - CÃ³digo modular es mÃ¡s fÃ¡cil de testear
   - Cambios localizados (no afectan todo)

5. **Deployment:**
   - Paquete instalable (`pip install atlasfx`)
   - Imports limpios
   - FÃ¡cil integraciÃ³n con CI/CD

### ğŸ¯ Estrategia: MigraciÃ³n Incremental

**NO** hacer big-bang rewrite. **SÃ** migrar por fases:
- Fase 1-2: Setup estructura
- Fase 3-5: Migrar mÃ³dulos uno a uno
- Mantener ambas estructuras temporalmente
- Deprecar old structure al finalizar MVP

**Timeline:** Se alinea perfectamente con el MVP Action Plan (12-18 semanas)

---

## Recursos y Referencias

### Best Practices
- [Python Packaging Guide](https://packaging.python.org/)
- [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/)
- [ML Project Template](https://github.com/ashleve/lightning-hydra-template)

### Ejemplos de Proyectos Bien Estructurados
- [PyTorch Lightning](https://github.com/Lightning-AI/lightning)
- [Hugging Face Transformers](https://github.com/huggingface/transformers)
- [Scikit-learn](https://github.com/scikit-learn/scikit-learn)

---

## PrÃ³ximos Pasos

1. **RevisiÃ³n:** Obtener approval de la estructura recomendada
2. **Setup:** Crear estructura bÃ¡sica (Fase 1)
3. **MigraciÃ³n:** Seguir plan incremental (Fases 2-5)
4. **ValidaciÃ³n:** Asegurar que tests pasan despuÃ©s de cada fase
5. **DocumentaciÃ³n:** Actualizar README con nueva estructura

---

**Autor:** AtlasFX Architecture Team  
**Fecha:** Octubre 2025  
**VersiÃ³n:** 1.0  
**Status:** Propuesta para AprobaciÃ³n
